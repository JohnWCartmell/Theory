
%\documentclass[prodmode,acmtods]{acmsmall}
\documentclass[10pt,a4paper]{article}
\input{../SharedMacros/ermacros}
\input{../SharedMacros/erdiagram}
\usepackage{mathtools}
\usepackage{alltt}
\usepackage{mnsymbol}
\usepackage{cmll}
\renewcommand{\ttdefault}{txtt}
\usepackage[font=small]{caption}
\setlength{\captionmargin}{2cm}


\begin{document}
\title{Relational Data Design Rewrite}

% abstract here for ams

\author{John Cartmell}

\maketitle
\begin{center}
DRAFT
\end{center}

\begin{abstract}
\noindent 
We present a formal framework for database specification that generalises  both Codd's relational data model and the post-Chen binary-relationship style entity relationship modelling (ER modelling) implemented, for instance, in Oracle's SQL developer tool and  described in the book of Barker.  We generalise the definitions of the most significant database normal forms (3NF, EKNF, IN-NF, 4NF, 5NF) and prove that from a well-formulated logical ER model there corresponds a relational model which is fully normalised. We conclude that the normalisation step in top-down relational data design is unnecessary.  
\end{abstract}

% comment out following for ams
%\bibliographystyle{hplain} 
\section{Introduction}


E.F.Codd's meta theory, presented as the relational model of data \cite{Codd1970},
 is a theory of \textit{what data is} and implementations of this theory have come to underpin 
the majority of corporate databases.   Codd and others described tests of goodness of a data schema applicable, it must be noted, only with cognisance to the possibilities among the data that it is designed to hold i.e. the intended usage.
In the first instance three tests were described and successively a schema is said to be is 1st normal form (1NF), 2nd normal form (2NF) or 3rd normal form (3NF) depending on its success in passing the tests. A process for fixing deficient schemas is described as normalisation of the schema. 
Normalisation is therefore a method for converting or transforming one relational schema into another deemed more suitable for the purpose at hand. 

In formal logical terms a relational schema presents a `theory of what is' and normalisation is the process of improving the theory by (i) tightening the theory to better fit the facts and (ii) removing redundancy from the presentation so that there be no redundancy in the data that is stored.

Subsequently, the relations of Codd's model are more abstractly presented, as either entities or as n-ary relationships, in Chen's entity-relationship model of data described in \cite{Chen1976}. 
Chen describes a method for constructing 
a relational schema (in the sense of Codd) from an entity-relationship schema (ER-schema).
He states that normalisation of the relational schema might be required after construction from an ER-schema -- though why this might be is not explained. 
This yields a design process which is a combination of automatic transformation followed by manual
normalisation and is said by Chen to be a top-down way to develop a relational schema in contrast to the Codd approach which he describes as bottom up.
Note that some authors\footnote{For example in Barker, Appendix A,  we find \textit{Entity relationship modeling tends to produce entities that are naturally normalized} and, in reference to entity relationship modelling, \textit{Following the above process  rigorously will automatically give a normalized model...}. } have mistakenly indicated that the second step within this workflow 
(the normalisation step) will likely be unnecessary if the ER-schema is itself free from redundancy
but there are many instances where within the limits of their meta-models this is not so and some are illustrated below. 

After Chen's 1976 paper, coming into and through the 1980's, came the development, concurrently, of Computer Aided Software Engineering (CASE) tools, including Meta-CASE tools, and semi-formalised and, in some instances, standardised official methodologies and notations, supporting structured systems analysis and development. Universally in the methodologies from this time the terms entity and relationship introduced in Chen's paper  were retained within a logical modelling phase and alongside Chen's transformational step into relational database design. Though the terms and the overall shape of the process is retained the concepts behind these terms are adjusted. Most noticeably `relationships' are now `binary relationships' and at an early stage in these methodologies many-many relationships are eliminated in favour of many-one relationships. At this point there has been a conceptual \textit{volte face} for a many-one  binary relationship, implementation considerations aside, is a thinly disguised pointer between records of a file, such as in a VSAM file system,  or a link between records in the network database model and it can be conceptualised, abstractly, as a function between sets of like-typed entities - leading some authors to describe a 
functional model of data \cite{Buneman1979},\cite{Shipman1981}. The entity-relationship diagrams of these software analysis  methods and the accompanying CASE tools
that emerged in the 80's bear more resemblance to notation that preceded the work of Codd and Chen such as to Bachman's data structure diagrams than to the diagrams of Chen.  
Among the many, and as summarised in  \cite{Rock-Evans1989},  there are three variants of binary entity relationship diagram that stand out, those found, respectively,  in SSADM/Barker-Ellis (now adopted by Oracle), in Clive Finkelstein and James Martin's Information Engineering,  and in IDEF.

In many cases, software methodologies and supporting CASE tools introduced an intermediate step between the ER model and the relational model naming the intermediary model the physical design model and the starting model the logical
model. This shifted the problem slightly but didn't make it go away. I shall call the automatic transformation relational models the Chen transform.  

We shall present a  definition of ER-schema which is general enough to include both purely logical schemas  and relational  schemas. We shall define the term ER model to mean an ER schema and all its intended usages and we shall show that by revising the definition of the Chen transform we can show that for each well-formulated purely logical schema there is a corresponding relational schema in normal form. 

In the terminology of Ellis\cite{ellis1982}, wherever in an entity model there is a path of single-valued relationships 
$\overset{r_1}{a \rightpitchfork \hspace{-0.35em} -  \cdot} \overset{r_2}{\rightpitchfork \hspace{-0.35em} -} \cdot ... \overset{r_n}{\rightpitchfork \hspace{-0.35em} -} b$
then the destination entity type $b$ is said to be in the \textit{logical horizon}  of the source entity type $a$. In programming, equivalently, 
we might say that it was possible to navigate from one to the other. Now if there are two such navigation paths between entity type $a$ (the source) and entity type $b$ (the destination) then a question naturally arises as to whether following one path is equivalent to
following the other i.e whether starting at any entity of type $a$ we arrive at the same destination entity of type $b$ regardless of which of the two paths we follow. In an abstract mathematical setting, diagrams showing such equivalent
paths are said to be \textit{commutative diagrams} and methods of reasoning using such diagrams is the starting point of category theory. 

Johnson and Dampney \cite{Johnson93} have emphasised the 
importance of recognising such commutative diagrams of 
relationships during entity modelling; 
in summary, there are identities between joins of derived 
relationships and these are important
and should be documented during the construction of an entity model. 
Johnson, Dampney and Wood in \cite{Johnson2002ERA} formulate a description of 
ER model that goes beyond the view of an ER schema as a directed graph 
by addition of constraints including commutative diagrams, cartesian products and 
pullbacks by defining an ER schema as a presentation of category with 
finite limits and colimits.  
A similar definition of a data model specification is given by Piessens and Steegman \cite{piessens1995}.
In a further paper, Johnson and Roseburgh \cite{Johnson2002REL} show the 
relationship between their formulation of ER models and relational models. 
These writers call for extensions to the notation employed by entity modellers so that ER schemas can be more expressive. Here we argue for this approach.  
Shlaer and Lang in \cite{Shlaer96} describe alternative paths between two entity types as relationship loops and when they are equivalent say that there are dependencies between the relationships.  
Kolp and Zimnyi (\cite{Kolp1995}) instead use the term relationship cycle and identify them as a source of 
superfluous attributes in the transformation from ER model to relational model. They say: \textit{ER cycles can be sources of 
superfluous attributes not detected by classical normalization. Hence, the interest of enhanced ER-based design methodologies that remove anomalies due to cycles and inclusion constraints.}


Chen's paper introduced the idea of entities being dependent on binary relationships 
with others for both their identification and their existence:

\begin{quote}
Theoretically, any kind of relationship may be used to identify entities. For
simplicity, we shall restrict ourselves to the use of only one kind of relationship:
the binary relationships with 1:n mapping in which the existence of the n entities
on one side of the relationship depends on the existence of one entity on the other
side of the relationship. For example, one employee may have n ( = 0, 1, 2, . . .)
dependants, and the existence of the dependants depends on the existence of the
corresponding employee.
This method of identification of entities by relationships with other entities can
be applied recursively until the entities which can be identified by their own attribute
values are reached. For example, the primary key of a department in a
company may consist of the department number and the primary key of the
division, which in turn consists of the division number and the name of the company.
\end{quote}


\section{Chen's Transformation}
\label{ChensTransformation}

Chen presents the transformation process from ER to relational by way of an example. 
He gives an example ER model and proceeds to say that from it that certain relations can `\textit{easily be derived}'\footnote{The verb \textit{migrate} is often used in descriptions of this process; for example I found a Wikipedia article describing a foreign key as a key that had migrated to another entity and I found a description elsewhere stating:
\begin{enumerate}
\item {Identify and define the primary key attributes for each entity}
\item {Validate primary keys and relationships}
\item {Migrate the primary keys to establish foreign keys}
\end{enumerate} The term `migrate' is inappropriate because key columns do not migrate anywhere - they stay where they are - what happens is that for each primary key column and for each relationship a corresponding foreign key column is instantiated.
}. 

In terms of the binary ER model the transformation illustrated by Chen can be summarised thus:
\begin{enumerate} [I]
	\item For each entity type on the diagram, a table is instantiated to represent the entity type.
  \item For each attribute of each entity type, a column is instantiated within the table
	      instantiated to represent the entity type. Specifically \textit{identifying}
				attributes are instantiated as primary key columns.
  \item For all identifying relationships,
	      primary key columns of the table representing the source of the relationship
				are instantiated --
				one per primary key column of the table representing the destination entity type.
  \item For all non-identifying relationships, columns of the table representing the
	      source entity type of the
	      relationship are instantiated one per primary key column of the 
				table representing the destination entity type.
\end{enumerate}

Another way of looking at the matter, rather than speaking of cascading and migrating keys, is based simply on the observation that the columns in the physical representation on an entity type $a$ correspond to the attributes of the entity type $a$ union the set of tuples $\langle r_1,...r_n, p \rangle$ where $n \geq 1$ and where
$\overset{r_1}{a \rightpitchfork \hspace{-0.35em} -  \cdot} \overset{r_2}{\rightpitchfork \hspace{-0.35em} -} \cdot ... \overset{r_n}{\rightpitchfork \hspace{-0.35em} -} b$ is a path of single-valued relationships, where 
$r_i$ is identifying for each $i > 1$ and where $p$ is an identifying attribute of the destination entity type $b$ of the
relationship $r_n$. This observation suggests a formal mathematical definition of the Chen transform and this is the approach we follow in Part Two. \\



\
\bibliographystyle{alpha} 
\bibliography{../SharedBibliography/temp/bibliography}
	 
\end{document}
